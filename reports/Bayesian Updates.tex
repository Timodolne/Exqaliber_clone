\documentclass[]{report}


% Title Page
\title{Bayesian Updates}
\usepackage{amsmath,amsthm,amssymb}


\begin{document}
\maketitle
\chapter{Preliminaries}

\section{Circular Distributions}
I'm anticipating that I might need to put more words into this later on, so am leaving space for them here.

\subsection{Von Mises distribution}
The Von-Mises distribution is given by:
\[
f(x, \mu, \kappa) = \frac{1}{2 \pi I_0{\kappa}} \exp(\kappa \cos(x-\mu)), \quad - \pi \le x \le \pi,
\]

where $I_0(\cdot)$ is the $0$th modified Bessel function, where the $n$th modified Bessel function is given by
\[
I_{n}(\kappa) = \frac{1}{\pi} \int_0^\pi \cos(n\theta) \exp(\kappa \cos \theta) \text{d}\theta.
\]

The circular mean of the Von-Mises distribution is given by:
 \[
	 \mathbb{E}\left[ \exp i  \theta \right]   = \frac{I_1\left( \kappa \right) }{I_0 \left( \kappa \right) }e^{i \mu}
.\]
In general, this can be seen via
\begin{align*}
	\mathbb{E} [e^{i n \theta}] &= \frac{1}{2\pi I_0 \left( \kappa \right) }\int_{-\pi}^{\pi}\exp\left( in \theta \right) \exp\left( \kappa \cos( \theta - \mu) \right) \text{d}\theta\\
				    &= \frac{1}{2\pi I_0\left( \kappa \right) }\int_{-\pi - \mu}^{\pi - \mu}\exp(in (\psi + \mu)) \exp\left( \kappa \cos\psi  \right) \text{d}\psi \\
				    &= \frac{e^{in \mu} }{2\pi I_0\left( \kappa \right) }\int_{-\pi}^{\pi} \exp\left( i n \theta \right) \exp \left( \kappa \cos\theta  \right) \text{d}\theta \\
				    &= \frac{e^{in \mu}}{2\pi I_0 (\kappa)} \int_{- \pi}^{\pi} \left( \cos( n \theta) + i \sin (n \theta)  \right) \exp\left( \kappa \cos \theta \right) \text{d} \theta \\
				    &= \frac{e^{in \mu}}{2\pi I_0\left( \kappa \right) } \int_{-\pi}^{\pi} \cos\left( n\theta \right)  \exp \left( \kappa \cos \theta \right) \text{d}\theta \\
				    &= \frac{I_{|n|}(\kappa)}{I_0(\kappa)} e^{i n \mu}. \\
\end{align*}
Note that we remove the $\sin$ integral by using the fact that the integral of an odd function over a symmetric, periodic interval is $0$.
\chapter{Problem Statement}
\section{Setup}
Goal: Given a single measurement of a Bernoulli random variable and a Von-Mises prior distribution, calculate the posterior distribution and approximate to a Von-Mises distribution.

\begin{itemize}
	\item $t$ - time step
	\item $d_t$ - Grover depth of quantum circuit at time $t$
	\item $Y_t$ - random variable representing a single shot measurement $y_t$ of the quantum circuit at time $t$
	\item $\Pi(\theta| Y_1 = y_1, \ldots, Y_t = y_t) = \Pi(\theta | \mathbf{Y}_t )$ - 'true' posterior at time $t$ (though values for $t ' < t$ have been used to approximate the earlier distributions)
	\item  $\hat{\Pi}(\theta| Y_1 = y_1, \ldots, Y_t = y_t) = \hat{\Pi}(\theta | \mathbf{Y}_t )$ - approximate posterior at time $t$.
\end{itemize}

According to Bayes rule:
\[
\Pi (\theta | Y_t = y_t, \mathbf{Y}_{t -1}) = \frac{\Pi(Y_t = y_t | \theta) \Pi(\theta | \mathbf{Y}_{t-1})}{\Pi(Y_t = y_t) },
\]
so we need to compute each of the quantities on the RHS.

At time $t$, we make a measurement $y_t$ of $Y_t \sim \text{Ber}(p_t)$ at a Grover depth of $d_t$ where
\[
	p_t = \frac{1}{2}(1 - \cos((4d_t + 2) \hat{\mu}_{t-1}).
\]
Thus,
\[
\Pi(Y_t = y_t | \theta) =  \frac{1}{2}(1 + (-1)^{y_t} \cos((4d_t + 2) \hat{\mu}_{t-1})).
\]
For convenience, let $\lambda_t = 4d_t + 2$.

To simplify some of the computations, we're going to assert that the posterior follows a Von-Mises distribution after every update, so we calculate the new values $\hat{\mu}_t, \hat{\kappa}_t$ and generate our approximate posterior
\[
\hat{\Pi}(\theta | \mathbf{Y}_t )  \sim VM(\hat{\mu}_t, \hat{\kappa}_t).
\]
\section{Single shot updates}
For simplicity, we're going to consider the first step of the update, which makes things a lot nicer. In this case, we want to know what the circular mean of the posterior distribution is after updating.

\begin{itemize}
	\item $\Pi(\theta) \sim \text{VM}(\mu, \kappa)$ - prior
	\item $\Pi(Y | \theta) \sim \text{Ber}(\frac{1}{2}(1 - \cos(\lambda \theta)))$
\end{itemize}

This gives us:
\begin{align*}
	\Pi(Y = y) &= \int_{-\pi}^{\pi} \Pi(Y = y | \theta) \Pi\left( \theta \right) \text{d}\theta \\
		   &= \frac{1}{2 \pi I_0(\kappa)} \int_{- \pi}^{\pi} \frac{1}{2} (1 + (-1)^y \cos(\lambda \theta)) \exp(\kappa \cos(\theta - \mu)) \text{d} \theta \\
	&= \frac{1}{2 \pi I_0(\kappa)} \left( \int_{- \pi}^{\pi} \frac{1}{2} \exp(\kappa \cos(\theta - \mu)) \text{d} \theta \right. \\
	 &\left. + (-1)^y \int_{- \pi}^{\pi} \frac{1}{2} \cos(\lambda \theta) \exp(\kappa \cos(\theta - \mu)) \text{d} \theta  \right) \\
	 &= \frac{1}{4 \pi I_0\left( \kappa \right) }\left( 2\pi I_0\left( \kappa \right)  + (-1)^{y} \int_{-\pi}^{\pi}\frac{e^{i \lambda \theta} + e^{-i \lambda \theta}}{2}\exp\left( \kappa \cos \left( \theta - \mu \right)  \right) \text{d}\theta \right) \\
	&= \frac{1}{2}\left(1 + (-1)^y \cos(\lambda \mu) \frac{I_\lambda(\kappa)}{I_0(\kappa)}\right)  \\
\end{align*}
where in the penultimate line, we use the expression for the $n$th circular moment.
Putting this all together, and letting

\[
C(y, \lambda, \mu, \kappa) = \frac{\frac{1}{2} \frac{1}{2 \pi I_0(\kappa)}}{\frac{1}{2} (1 + (-1)^y \cos(\lambda \mu) \frac{I_\lambda(\kappa)}{I_0(\kappa)} )} = \frac{1}{ 2 \pi(I_0(\kappa) + (-1)^y \cos(\lambda \mu) I_\lambda(\kappa))}
\]
gives

\begin{align*}
	\mathbb{E}[e^{i \theta} | Y = y] &= C(y, \lambda,\mu, \kappa) \int_{- \pi}^{\pi} e^{i \theta} (1 + (-1)^y \cos(\lambda \theta)) \exp(\kappa \cos(\theta - \mu)) \text{d} \theta \\
& =	C(y, \lambda,\mu, \kappa) \left(  \int_{- \pi}^{\pi} e^{i \theta} \exp(\kappa \cos(\theta - \mu)) \text{d} \theta \right. \\
 & \quad + (-1)^y  \left. \int_{- \pi}^{\pi} e^{i \theta} \cos(\lambda \theta)   \exp(\kappa \cos(\theta - \mu)) \text{d} \theta \right)\\
 &= C(y, \lambda,\mu, \kappa) \left( \vphantom{\int_{-\pi}^\pi} 2 \pi I_1(\kappa) e^{i \mu} \right. \\
 &\quad \left.+ (-1)^y  \int_{-\pi}^{\pi} e^{i \theta} \left( \frac{e^{i \lambda \theta} + e^{- i \lambda \theta}}{2}\right)  \exp(\kappa \cos(\theta - \mu)) \text{d} \theta \right) \\
 &= 2 \pi C(y, \lambda,\mu, \kappa) \left( I_1(\kappa) e^{i \mu} + \frac{(-1)^y}{2} \left(I_{\lambda + 1}(\kappa)e^{i(\lambda + 1) \mu}  + I_{\lambda - 1}(\kappa) e^{-i(\lambda - 1)\mu}\right) \right)
\end{align*}
where in the penultimate line, we use the fact that
\[
\int_{- \pi}^ \pi e^{i n \theta} \exp(\kappa \cos(\theta - \mu)) \text{d} \theta = 2 \pi I_0(\kappa) \mathbb{E}[e^{i n \theta}] = I_{|n|}(\kappa) e^{i n \mu}.
\]

This gives us that
\[
\mathbb{E}[e^{i \theta} | Y = y] = \frac{ I_1(\kappa) e^{i \mu} + \frac{(-1)^y}{2} \left(I_{\lambda + 1}(\kappa)e^{i(\lambda + 1) \mu}  + I_{\lambda - 1}(\kappa) e^{-i(\lambda - 1)\mu}\right)}{I_0(\kappa) + (-1)^y \cos(\lambda \mu) I_\lambda(\kappa)}.
\]

If we then take expectations over $Y$ (i.e. multiply by $\Pi(Y = y))$ and sum) this gives us

\[
\mathbb{E}[e^{i \theta}] = \frac{I_{1}(\kappa)}{I_0(\kappa)}e^{i \mu}.
\]
So, we can infer that we do not expect the angular parameter $\mu$ to move. To infer something about $\kappa$, we need to consider $\mathbb{E}[R]$. As before, let's consider $\mathbb{E}[R | Y = y]$. From the above, we can deduce that
 \begin{align*}
	 \mathbb{E}[R | Y = y]^{2} &= \frac{\left( I_1 + \frac{(-1)^{y}}{2}\left( e^{i \lambda \mu}I_{\lambda + 1}+ e^{- i \lambda \mu}I_{\lambda -1} \right)  \right) \left( I_1 + \frac{(-1)^{y}}{2}\left( e^{-i \lambda \mu}I_{\lambda + 1} + e^{i \lambda \mu} I_{\lambda -1 } \right)  \right) }{\left( I_0 + (-1)^{y}\cos(\lambda \mu) I_{\lambda} \right)^{2} } \\
				   &= \frac{I_1^{2} + \frac{1}{4}\left( I_{\lambda + 1}^2 + I_{\lambda - 1}^2 \right) +\frac{1}{2} \cos\left( 2 \lambda \mu \right)  I_{\lambda +1}I_{\lambda - 1} + (-1)^{y} I_1\left( I_{\lambda + 1} + I_{\lambda - 1} \right) \cos \lambda \mu}{\left( I_0 + (-1)^{y}\cos (\lambda \mu) I_{\lambda} \right) ^2} \\
				   &= \frac{N_y^2}{\left( I_0 + (-1)^{y}\cos(\lambda \mu) I_{\lambda} \right) ^2},
\end{align*}
where for brevity, we have suppressed the argument $\kappa$ for each of the Bessel functions $I_{\nu}$.

Calculating $\mathbb{E}[R]$ then, is achieved by multiplying by  $\Pi(Y = y)$, square-rooting, and summing. This results in the sum of the square roots of the numerators multiplied by a constant factor of $\frac{1}{2 I_0(\kappa)}$, i.e.

\begin{align*}
	\mathbb{E}[R] &= \frac{N_0 + N_1}{2 I_0(\kappa)} \\
		      &= \frac{1}{2 I_0(\kappa) } \sqrt{I_1^2 + \frac{1}{4} \left( I_{\lambda + 1}^{2} + I_{\lambda - 1}^2 \right)  + \frac{1}{2}\cos(2 \lambda \mu) I_{\lambda +1} I_{\lambda - 1} + I_1 \left( I_{\lambda + 1} + I_{\lambda -1 } \right) \cos (\lambda \mu) } \\
		      & + \frac{1}{2 I_0(\kappa) } \sqrt{I_1^2 + \frac{1}{4} \left( I_{\lambda + 1}^{2} + I_{\lambda - 1}^2 \right)  + \frac{1}{2}\cos(2 \lambda \mu) I_{\lambda +1} I_{\lambda - 1} - I_1 \left( I_{\lambda + 1} + I_{\lambda -1 } \right) \cos (\lambda \mu) }
\end{align*}

\appendix

\chapter{Integrals}
\section{Normal Distribution}
First, let us note that
\[
\frac{\text{d}}{\text{d}x}(e^{- x^2}) = - 2 x e^{ - x ^2}
.\]
The integrals we are interested in computing, are either of the form
\[
	I_{2n}(k) = \int_{- \infty}^{\infty} \theta^{2n} \cos (k \theta) e^{ - \theta^2}\text{d}\theta \text{ or } I_{2n + 1} = \int_{- \infty}^{\infty} \theta^{2n + 1} \sin (k \theta) e^{ - \theta^2}\text{d} \theta
\]


\end{document}
